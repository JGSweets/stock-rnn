{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import pprint\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.contrib.slim as slim\n",
    "\n",
    "from data_model import StockDataSet\n",
    "from model_rnn import LstmRNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "flags = tf.app.flags\n",
    "flags.DEFINE_integer(\"stock_count\", 100, \"Stock count [100]\")\n",
    "flags.DEFINE_integer(\"input_size\", 5, \"Input size [5]\")\n",
    "flags.DEFINE_integer(\"num_steps\", 30, \"Num of steps [30]\")\n",
    "flags.DEFINE_integer(\"num_layers\", 1, \"Num of layer [1]\")\n",
    "flags.DEFINE_integer(\"lstm_size\", 128, \"Size of one LSTM cell [128]\")\n",
    "flags.DEFINE_integer(\"batch_size\", 64, \"The size of batch images [64]\")\n",
    "flags.DEFINE_float(\"keep_prob\", 0.8, \"Keep probability of dropout layer. [0.8]\")\n",
    "flags.DEFINE_float(\"init_learning_rate\", 0.001, \"Initial learning rate at early stage. [0.001]\")\n",
    "flags.DEFINE_float(\"learning_rate_decay\", 0.99, \"Decay rate of learning rate. [0.99]\")\n",
    "flags.DEFINE_integer(\"init_epoch\", 5, \"Num. of epoches considered as early stage. [5]\")\n",
    "flags.DEFINE_integer(\"max_epoch\", 50, \"Total training epoches. [50]\")\n",
    "flags.DEFINE_integer(\"embed_size\", None, \"If provided, use embedding vector of this size. [None]\")\n",
    "flags.DEFINE_string(\"stock_symbol\", 'SP500', \"Target stock symbol [None]\")\n",
    "flags.DEFINE_string(\"checkpoint_dir\", \"checkpoints\", \"Directory name to save the checkpoints [checkpoints]\")\n",
    "flags.DEFINE_integer(\"sample_size\", 4, \"Number of stocks to plot during training. [4]\")\n",
    "flags.DEFINE_string(\"plot_dir\", \"images\", \"Directory name to save plots [images]\")\n",
    "flags.DEFINE_boolean(\"train\", True, \"True for training, False for testing [False]\")\n",
    "\n",
    "FLAGS = flags.FLAGS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pp = pprint.PrettyPrinter()\n",
    "\n",
    "if not os.path.exists(\"logs\"):\n",
    "    os.mkdir(\"logs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_all_variables():\n",
    "    model_vars = tf.trainable_variables()\n",
    "    slim.model_analyzer.analyze_vars(model_vars, print_info=True)\n",
    "\n",
    "\n",
    "def load_sp500(input_size, num_steps, k=None, target_symbol=None, test_ratio=0.05):\n",
    "    if target_symbol is not None:\n",
    "        return [\n",
    "            StockDataSet(\n",
    "                target_symbol,\n",
    "                input_size=input_size,\n",
    "                num_steps=num_steps,\n",
    "                test_ratio=test_ratio)\n",
    "        ]\n",
    "    # Load metadata of s & p 500 stocks\n",
    "    info = pd.read_csv(\"data/constituents-financials.csv\")\n",
    "    info = info.rename(columns={col: col.lower().replace(' ', '_') for col in info.columns})\n",
    "    info['file_exists'] = info['symbol'].map(lambda x: os.path.exists(\"data/{}.csv\".format(x)))\n",
    "    print info['file_exists'].value_counts().to_dict()\n",
    "\n",
    "    info = info[info['file_exists'] == True].reset_index(drop=True)\n",
    "    info = info.sort('market_cap', ascending=False).reset_index(drop=True)\n",
    "\n",
    "    if k is not None:\n",
    "        info = info.head(k)\n",
    "\n",
    "    print \"Head of S&P 500 info:\\n\", info.head()\n",
    "\n",
    "    # Generate embedding meta file\n",
    "    info[['symbol', 'sector']].to_csv(os.path.join(\"logs/metadata.tsv\"), sep='\\t', index=False)\n",
    "\n",
    "    return [\n",
    "        StockDataSet(row['symbol'],\n",
    "                     input_size=input_size,\n",
    "                     num_steps=num_steps,\n",
    "                     test_ratio=0.05)\n",
    "        for _, row in info.iterrows()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(_):\n",
    "    \n",
    "    from IPython.core.debugger import Tracer\n",
    "    Tracer()()\n",
    "    \n",
    "    pp.pprint(flags.FLAGS.__flags)\n",
    "\n",
    "    if not os.path.exists(FLAGS.checkpoint_dir):\n",
    "        os.makedirs(FLAGS.checkpoint_dir)\n",
    "\n",
    "    if not os.path.exists(FLAGS.plot_dir):\n",
    "        os.makedirs(FLAGS.plot_dir)\n",
    "\n",
    "    # gpu_options = tf.GPUOptions(per_process_gpu_memory_fraction=0.333)\n",
    "    run_config = tf.ConfigProto()\n",
    "    run_config.gpu_options.allow_growth = True\n",
    "\n",
    "    with tf.Session(config=run_config) as sess:\n",
    "        rnn_model = LstmRNN(\n",
    "            sess,\n",
    "            FLAGS.stock_count,\n",
    "            lstm_size=FLAGS.lstm_size,\n",
    "            num_layers=FLAGS.num_layers,\n",
    "            num_steps=FLAGS.num_steps,\n",
    "            input_size=FLAGS.input_size,\n",
    "            keep_prob=FLAGS.keep_prob,\n",
    "            embed_size=FLAGS.embed_size,\n",
    "            checkpoint_dir=FLAGS.checkpoint_dir,\n",
    "        )\n",
    "\n",
    "        show_all_variables()\n",
    "\n",
    "        stock_data_list = load_sp500(\n",
    "            FLAGS.input_size,\n",
    "            FLAGS.num_steps,\n",
    "            k=FLAGS.stock_count,\n",
    "            target_symbol=FLAGS.stock_symbol,\n",
    "        )\n",
    "\n",
    "        if FLAGS.train:\n",
    "            rnn_model.train(stock_data_list, FLAGS)\n",
    "        else:\n",
    "            if not rnn_model.load()[0]:\n",
    "                raise Exception(\"[!] Train a model first, then run test mode\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel_launcher.py:4: DeprecationWarning: `Tracer` is deprecated since version 5.1, directly use `IPython.core.debugger.Pdb.set_trace()`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m<ipython-input-5-7adea3fb3b6c>\u001b[0m(6)\u001b[0;36mmain\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m      4 \u001b[0;31m    \u001b[0mTracer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      5 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m----> 6 \u001b[0;31m    \u001b[0mpp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__flags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      7 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m      8 \u001b[0;31m    \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFLAGS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcheckpoint_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> c\n",
      "{'batch_size': 64,\n",
      " 'checkpoint_dir': 'checkpoints',\n",
      " 'embed_size': None,\n",
      " 'init_epoch': 5,\n",
      " 'init_learning_rate': 0.001,\n",
      " 'input_size': 5,\n",
      " 'keep_prob': 0.8,\n",
      " 'learning_rate_decay': 0.99,\n",
      " 'lstm_size': 128,\n",
      " 'max_epoch': 50,\n",
      " 'num_layers': 1,\n",
      " 'num_steps': 30,\n",
      " 'plot_dir': 'images',\n",
      " 'sample_size': 4,\n",
      " 'stock_count': 100,\n",
      " 'stock_symbol': 'SP500',\n",
      " 'train': True}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/tensorflow/python/ops/gradients_impl.py:95: UserWarning: Converting sparse IndexedSlices to a dense Tensor of unknown shape. This may consume a large amount of memory.\n",
      "  \"Converting sparse IndexedSlices to a dense Tensor of unknown shape. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------\n",
      "Variables: name (type shape) [size]\n",
      "---------\n",
      "dynamic_rnn/lstm_cell/kernel:0 (float32_ref 133x512) [68096, bytes: 272384]\n",
      "dynamic_rnn/lstm_cell/bias:0 (float32_ref 512) [512, bytes: 2048]\n",
      "w:0 (float32_ref 128x5) [640, bytes: 2560]\n",
      "b:0 (float32_ref 5) [5, bytes: 20]\n",
      "Total size of variables: 69253\n",
      "Total bytes of variables: 277012\n",
      "len(merged_test_X) = 169\n",
      "len(merged_test_y) = 169\n",
      "len(merged_test_labels) = 169\n",
      "{'SP500': array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
      "        13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
      "        26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
      "        39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
      "        52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
      "        65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
      "        78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
      "        91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
      "       104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
      "       117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
      "       130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
      "       143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
      "       156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168])}\n",
      "Start training for stocks: ['SP500']\n",
      "Step:1 [Epoch:0] [Learning rate: 0.001000] train_loss:0.009998 test_loss:0.009068\n",
      "Step:101 [Epoch:2] [Learning rate: 0.001000] train_loss:0.000787 test_loss:0.000861\n",
      "Step:201 [Epoch:4] [Learning rate: 0.001000] train_loss:0.001055 test_loss:0.000668\n",
      "Step:301 [Epoch:6] [Learning rate: 0.000980] train_loss:0.000822 test_loss:0.000625\n",
      "Step:401 [Epoch:8] [Learning rate: 0.000961] train_loss:0.000531 test_loss:0.000436\n",
      "Step:501 [Epoch:10] [Learning rate: 0.000941] train_loss:0.000267 test_loss:0.000323\n",
      "Step:601 [Epoch:12] [Learning rate: 0.000923] train_loss:0.000537 test_loss:0.000289\n",
      "Step:701 [Epoch:14] [Learning rate: 0.000904] train_loss:0.000316 test_loss:0.000377\n",
      "Step:801 [Epoch:16] [Learning rate: 0.000886] train_loss:0.000245 test_loss:0.000309\n",
      "Step:901 [Epoch:18] [Learning rate: 0.000869] train_loss:0.000289 test_loss:0.000252\n",
      "Step:1001 [Epoch:20] [Learning rate: 0.000851] train_loss:0.000147 test_loss:0.000250\n",
      "Step:1101 [Epoch:22] [Learning rate: 0.000835] train_loss:0.000215 test_loss:0.000265\n",
      "Step:1201 [Epoch:24] [Learning rate: 0.000818] train_loss:0.001120 test_loss:0.000285\n",
      "Step:1301 [Epoch:26] [Learning rate: 0.000802] train_loss:0.000698 test_loss:0.000257\n",
      "Step:1401 [Epoch:28] [Learning rate: 0.000786] train_loss:0.000506 test_loss:0.000232\n",
      "Step:1501 [Epoch:30] [Learning rate: 0.000770] train_loss:0.000412 test_loss:0.000226\n",
      "Step:1601 [Epoch:32] [Learning rate: 0.000755] train_loss:0.000195 test_loss:0.000217\n",
      "Step:1701 [Epoch:34] [Learning rate: 0.000740] train_loss:0.000092 test_loss:0.000229\n",
      "Step:1801 [Epoch:36] [Learning rate: 0.000725] train_loss:0.000279 test_loss:0.000218\n",
      "Step:1901 [Epoch:38] [Learning rate: 0.000711] train_loss:0.000560 test_loss:0.000273\n",
      "Step:2001 [Epoch:40] [Learning rate: 0.000696] train_loss:0.000449 test_loss:0.000219\n",
      "Step:2101 [Epoch:42] [Learning rate: 0.000683] train_loss:0.000337 test_loss:0.000226\n",
      "Step:2201 [Epoch:44] [Learning rate: 0.000669] train_loss:0.000146 test_loss:0.000236\n",
      "Step:2301 [Epoch:46] [Learning rate: 0.000656] train_loss:0.000163 test_loss:0.000226\n",
      "Step:2401 [Epoch:48] [Learning rate: 0.000643] train_loss:0.000464 test_loss:0.000219\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-cf34dbe789c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/tensorflow/python/platform/app.pyc\u001b[0m in \u001b[0;36mrun\u001b[0;34m(main, argv)\u001b[0m\n\u001b[1;32m     46\u001b[0m   \u001b[0;31m# Call the main function, passing through any arguments\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# to the final program.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m   \u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_sys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margv\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mflags_passthrough\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mSystemExit\u001b[0m: "
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FLAGS"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
